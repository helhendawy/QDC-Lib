{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGIE QTEM Data Challenge ‚Äì 2025  \n",
    "\n",
    "This notebook is a comprehensive and reproducible workflow to solve the ENGIE QTEM Data Challenge. The challenge is focused on optimizing a renewable energy asset portfolio based on weather, production, and market pricing data.\n",
    "\n",
    "### Key Business Questions:\n",
    "- Which combination of renewable energy assets yields the highest production with the least variability?\n",
    "- How do revenue considerations (market price data) affect the optimal portfolio selection?\n",
    "- What are the differences between production-driven and revenue-driven optimization?\n",
    "- How would the results change if real-world inefficiencies (e.g. curtailments) were removed?\n",
    "\n",
    "---\n",
    "\n",
    "### Final Deliverables:\n",
    "- Reproducible optimization models (production & revenue)\n",
    "- Portfolio performance metrics (mean output, standard deviation, volatility)\n",
    "- Comparative analysis & sensitivity insights\n",
    "- Final report and presentation-ready visualizations\n",
    "\n",
    "---\n",
    "\n",
    "### Data Overview:\n",
    "- **Solar Production Sites:** 71 (Belgium, Germany, Netherlands)\n",
    "- **Wind Sites:** 99 (onshore + offshore)\n",
    "- **Weather Variables:** Temperature, wind speed/direction, cloud cover, solar radiation\n",
    "- **Prices:** Quarter-hourly and hourly market prices (Day-Ahead, Intraday, ISP)\n",
    "- **Metadata:** Site locations, variable definitions\n",
    "\n",
    "---\n",
    "\n",
    "## Available Data:\n",
    "\n",
    "- **Solar Data Folder:** Contains files for each solar site:\n",
    "  - Dew Point (`d2m`)\n",
    "  - Total Cloud Cover (`tcc`)\n",
    "  - Temperature (`t2m`)\n",
    "  - Solar Radiation (`ssr`)\n",
    "  - Wind Angle at 10m (`angle10`)\n",
    "  - Wind Speed at 10m (`speed10`)\n",
    "  - Load Factor (`factor`)\n",
    "\n",
    "- **Wind Data Folder:** Contains files for each wind site:\n",
    "  - Wind Angle at 100m (`angle100`)\n",
    "  - Wind Speed at 100m (`speed100`)\n",
    "  - Load Factor (`factor`)\n",
    "\n",
    "- **Price and Liquidity Data:**\n",
    "  - Day Ahead and Intraday prices.\n",
    "\n",
    "- **Additional Files:**\n",
    "  - Sites anonymized data (`sites_anonymized.csv`)\n",
    "  - Data Dictionary (`data_dictionary.xlsx`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Comprehensive Data Assessment\n",
    "\n",
    "In this section, we:\n",
    "- Explore metadata to understand the site distribution\n",
    "- Examine weather, production, and price data structure\n",
    "- Identify missing values, timestamp irregularities, and data format issues\n",
    "- Prepare for integration and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Price & Liquidity Data Cleaning Summary\n",
    "\n",
    "We started with a raw pricing dataset containing 59 columns and 132,310 timestamped records, covering multiple market types (Day-Ahead, Intraday, Imbalance) across Belgium (BE), Germany (DE), the Netherlands (NL), and France (FR).\n",
    "\n",
    "#### ‚úÖ Actions Taken:\n",
    "- Removed all `volume` columns, which are not required in the ENGIE optimization objective (no use for liquidity or transaction volume).\n",
    "- Dropped all columns related to France (`FR`) since the challenge scope is limited to BE, DE, and NL.\n",
    "- Excluded rarely populated or redundant formats such as half-hour (HH) pricing and kept only **Hourly and Quarter-Hourly (QH)** series where reasonably populated.\n",
    "- Retained all Day-Ahead (`DA_*`) pricing columns.\n",
    "- Retained relevant Intraday pricing layers: `ID1`, `ID3`, and `IDFull`, for both `Hourly` and `QH` formats.\n",
    "- Retained flat imbalance prices `ISP_*`, as well as `ISP_SHORT_NL` and `ISP_LONG_NL` for modeling imbalance market logic in Part 2 or Part 4.\n",
    "\n",
    "#### üì¶ Resulting Dataset:\n",
    "- Final shape: **132,310 rows √ó 26 columns**\n",
    "- Includes all pricing columns required for Parts **2, 3, and 4** of the challenge.\n",
    "- Structured to support reproducible modeling and easy merging with production and weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/8x4b66f12jxblmgjlz1qymv80000gn/T/ipykernel_1871/3748134077.py:7: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  price_df['datetime'] = pd.to_datetime(price_df['datetime'])\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "sites_df = pd.read_csv(\"/Users/hossameldinelhendawy/Documents/QDC-Lib/sites_anonymized.csv\")\n",
    "price_df = pd.read_csv(\"/Users/hossameldinelhendawy/Documents/QDC-Lib/intraday_indices_prices_and_liquidity.csv\")\n",
    "\n",
    "# Datetime column modification\n",
    "price_df.rename(columns={price_df.columns[0]: \"datetime\"}, inplace=True)\n",
    "price_df['datetime'] = pd.to_datetime(price_df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of relevant price columns for Parts 1‚Äì4\n",
    "columns_to_keep = ['datetime']\n",
    "\n",
    "# Add DA prices\n",
    "for country in ['BE', 'DE', 'NL']:\n",
    "    col = f'DA_{country}'\n",
    "    if col in price_df.columns:\n",
    "        columns_to_keep.append(col)\n",
    "\n",
    "# Add hourly and QH intraday prices\n",
    "intraday_types = ['ID1', 'ID3', 'IDFull']\n",
    "resolutions = ['Hourly', 'QH']\n",
    "\n",
    "for market in intraday_types:\n",
    "    for resolution in resolutions:\n",
    "        for country in ['BE', 'DE', 'NL']:\n",
    "            col = f'{market}_{resolution}_{country}_price'\n",
    "            if col in price_df.columns:\n",
    "                columns_to_keep.append(col)\n",
    "\n",
    "# Add Imbalance prices\n",
    "for country in ['BE', 'DE', 'NL']:\n",
    "    # Flat ISP\n",
    "    col_flat = f'ISP_{country}'\n",
    "    if col_flat in price_df.columns:\n",
    "        columns_to_keep.append(col_flat)\n",
    "    # NL-specific imbalance split\n",
    "    col_short = f'ISP_SHORT_{country}'\n",
    "    col_long = f'ISP_LONG_{country}'\n",
    "    if col_short in price_df.columns:\n",
    "        columns_to_keep.append(col_short)\n",
    "    if col_long in price_df.columns:\n",
    "        columns_to_keep.append(col_long)\n",
    "\n",
    "# Apply filter\n",
    "price_cleaned_df = price_df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÄÔ∏è Solar Data Preprocessing Summary\n",
    "\n",
    "We prepared the solar dataset for modeling by executing the following structured pipeline:\n",
    "\n",
    "### 1. Site Discovery & Variable Definition\n",
    "- Loaded all `.csv` files from the solar folder\n",
    "- Extracted 71 unique site IDs\n",
    "- Defined the target variables:  \n",
    "  - Weather: `d2m`, `tcc`, `t2m`, `ssr`, `angle10`, `speed10`  \n",
    "  - Production: `load_factor`\n",
    "\n",
    "### 2. Per-Site Loading & Merging\n",
    "- For each site, we loaded its 7 variable files\n",
    "- Parsed and standardized the `datetime` column\n",
    "- Merged all variables on `datetime`\n",
    "- Added a `site_id` column\n",
    "- Stored the result in `solar_site_data[site_id]`\n",
    "\n",
    "### 3. Timeline Construction\n",
    "- Extracted all timestamps across all sites\n",
    "- Built a unified hourly index:\n",
    "  - Start: `2018-12-31 23:00:00`\n",
    "  - End: `2024-10-01 00:00:00`\n",
    "  - Total timestamps: `50,402`\n",
    "  - Frequency: **Hourly**\n",
    "\n",
    "### 4. Site Reindexing\n",
    "- Reindexed every site‚Äôs dataframe to the unified hourly timeline\n",
    "- Preserved missing data as `NaN`\n",
    "- Stored aligned sites in `solar_site_data_aligned`\n",
    "\n",
    "### 5. Final Stacking\n",
    "- Combined all aligned sites into a single dataframe `solar_all_df`\n",
    "- Shape: `3,578,542 rows √ó 9 columns`\n",
    "- Columns: `datetime`, 6 weather vars, `load_factor`, `site_id`\n",
    "- Verified 71 unique sites and 50,402 hourly timestamps\n",
    "\n",
    "This cleaned dataset is now ready for merging with price data and optimization in Phases 2 and 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path\n",
    "solar_path = \"/Users/hossameldinelhendawy/Documents/QDC-Lib/solar\"\n",
    "\n",
    "# All solar files\n",
    "solar_files = glob(os.path.join(solar_path,\"*.csv\"))\n",
    "\n",
    "# Extract site IDs from filenames\n",
    "solar_site_ids = sorted(\n",
    "    list(set([f.split('_')[-1].replace('.csv', '') for f in solar_files]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables per site\n",
    "solar_vars = ['d2m', 'tcc', 't2m', 'ssr', 'angle10', 'speed10', 'load_factor']\n",
    "\n",
    "def load_solar_site_data(site_id, folder_path):\n",
    "    dfs = []\n",
    "    \n",
    "    for var in solar_vars:\n",
    "        if var == 'load_factor':\n",
    "            file_name = f'load_factor_{site_id}.csv'\n",
    "        else:\n",
    "            file_name = f'era5_{var}_{site_id}.csv'\n",
    "        \n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"[WARNING] Missing file for {var} at site {site_id}\")\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Rename datetime column and parse\n",
    "        df.rename(columns={df.columns[0]: 'datetime'}, inplace=True)\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        \n",
    "        # Rename value column to the variable name\n",
    "        df.rename(columns={df.columns[1]: var}, inplace=True)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    if not dfs:\n",
    "        print(f\"[ERROR] No data found for site {site_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Merge on datetime\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='datetime', how='outer')\n",
    "    \n",
    "    merged_df['site_id'] = site_id\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract solar sites files into one dict\n",
    "solar_site_data = {}\n",
    "\n",
    "for site_id in solar_site_ids:\n",
    "    try:\n",
    "        merged_site_df = load_solar_site_data(site_id, solar_path)\n",
    "        if merged_site_df is not None:\n",
    "            solar_site_data[site_id] = merged_site_df\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load site {site_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÜ Datetime coverage:\n",
      "Start: 2018-12-31 23:00:00+00:00\n",
      "End  : 2024-10-01 00:00:00+00:00\n",
      "\n",
      "üïí Time interval frequencies:\n",
      "0 days 01:00:00    50401\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üî¢ Total unique timestamps: 50402\n"
     ]
    }
   ],
   "source": [
    "# Collect all datetime values from all sites\n",
    "datetime_series_list = [df['datetime'] for df in solar_site_data.values()]\n",
    "all_timestamps = pd.concat(datetime_series_list, ignore_index=True)\n",
    "\n",
    "# Drop duplicates and sort\n",
    "all_timestamps = pd.to_datetime(all_timestamps.unique())\n",
    "all_timestamps = pd.Series(sorted(all_timestamps))\n",
    "\n",
    "# Inspect time coverage and frequency\n",
    "print(\"üìÜ Datetime coverage:\")\n",
    "print(\"Start:\", all_timestamps.min())\n",
    "print(\"End  :\", all_timestamps.max())\n",
    "print(\"\\nüïí Time interval frequencies:\")\n",
    "print(all_timestamps.diff().value_counts().head())\n",
    "print(\"\\nüî¢ Total unique timestamps:\", len(all_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reindexing sites: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71/71 [00:00<00:00, 84.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Align each site to the master datetime index\n",
    "\n",
    "# Create the master datetime index (hourly)\n",
    "datetime_index = pd.DatetimeIndex(all_timestamps)\n",
    "\n",
    "# New dictionary to hold reindexed data\n",
    "solar_site_data_aligned = {}\n",
    "\n",
    "# Use tqdm to track loading progress\n",
    "for site_id, df in tqdm(solar_site_data.items(), desc=\"Reindexing sites\"):\n",
    "    df = df.set_index('datetime')\n",
    "    \n",
    "    # Reindex to fill in all missing timestamps with NaNs\n",
    "    df = df.reindex(datetime_index)\n",
    "    \n",
    "    # Keep the site_id in a column\n",
    "    df['site_id'] = site_id\n",
    "    \n",
    "    # Store in the new aligned dictionary\n",
    "    df.index.name = 'datetime'\n",
    "    solar_site_data_aligned[site_id] = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample site: 026396\n",
      "Rows: 50402\n",
      "Expected rows: 50402\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "d2m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tcc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t2m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ssr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "angle10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "speed10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "load_factor",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e61510d0-5e68-4ed4-acf4-c6bbd5ac20e0",
       "rows": [
        [
         "0",
         "2018-12-31 23:00:00+00:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "026396"
        ],
        [
         "1",
         "2019-01-01 00:00:00+00:00",
         "279.73291015625",
         "1.0",
         "281.1588439941406",
         "0.0",
         "0.1795746154797828",
         "3.3959695270888948",
         "8.370535714285714e-05",
         "026396"
        ],
        [
         "2",
         "2019-01-01 01:00:00+00:00",
         "279.1694030761719",
         "0.94149512052536",
         "280.8376770019531",
         "0.0",
         "0.2286955322921844",
         "3.4025789222907967",
         "8.426339285714286e-05",
         "026396"
        ],
        [
         "3",
         "2019-01-01 02:00:00+00:00",
         "278.66912841796875",
         "0.9989928603172302",
         "280.65997314453125",
         "0.0",
         "0.2266694432734434",
         "3.528859901378381",
         "8.537946428571428e-05",
         "026396"
        ],
        [
         "4",
         "2019-01-01 03:00:00+00:00",
         "278.27423095703125",
         "0.9902338981628418",
         "280.5801086425781",
         "0.0",
         "0.2848088968374169",
         "3.6035858398502567",
         "8.426339285714286e-05",
         "026396"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>d2m</th>\n",
       "      <th>tcc</th>\n",
       "      <th>t2m</th>\n",
       "      <th>ssr</th>\n",
       "      <th>angle10</th>\n",
       "      <th>speed10</th>\n",
       "      <th>load_factor</th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:00+00:00</td>\n",
       "      <td>279.732910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>281.158844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179575</td>\n",
       "      <td>3.395970</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 01:00:00+00:00</td>\n",
       "      <td>279.169403</td>\n",
       "      <td>0.941495</td>\n",
       "      <td>280.837677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>3.402579</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 02:00:00+00:00</td>\n",
       "      <td>278.669128</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>280.659973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226669</td>\n",
       "      <td>3.528860</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 03:00:00+00:00</td>\n",
       "      <td>278.274231</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>280.580109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284809</td>\n",
       "      <td>3.603586</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime         d2m       tcc         t2m  ssr   angle10  \\\n",
       "0 2018-12-31 23:00:00+00:00         NaN       NaN         NaN  NaN       NaN   \n",
       "1 2019-01-01 00:00:00+00:00  279.732910  1.000000  281.158844  0.0  0.179575   \n",
       "2 2019-01-01 01:00:00+00:00  279.169403  0.941495  280.837677  0.0  0.228696   \n",
       "3 2019-01-01 02:00:00+00:00  278.669128  0.998993  280.659973  0.0  0.226669   \n",
       "4 2019-01-01 03:00:00+00:00  278.274231  0.990234  280.580109  0.0  0.284809   \n",
       "\n",
       "    speed10  load_factor site_id  \n",
       "0       NaN          NaN  026396  \n",
       "1  3.395970     0.000084  026396  \n",
       "2  3.402579     0.000084  026396  \n",
       "3  3.528860     0.000085  026396  \n",
       "4  3.603586     0.000084  026396  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a sample site to check\n",
    "sample_id = list(solar_site_data_aligned.keys())[0]\n",
    "sample_df = solar_site_data_aligned[sample_id]\n",
    "\n",
    "print(f\"‚úÖ Sample site: {sample_id}\")\n",
    "print(\"Rows:\", sample_df.shape[0])\n",
    "print(\"Expected rows:\", len(datetime_index))\n",
    "display(sample_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined solar dataset shape: (3578542, 9)\n",
      "üîç Columns: ['datetime', 'd2m', 'tcc', 't2m', 'ssr', 'angle10', 'speed10', 'load_factor', 'site_id']\n",
      "üìå Unique site IDs: 71\n",
      "üìÜ Unique timestamps: 50402\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "d2m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tcc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t2m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ssr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "angle10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "speed10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "load_factor",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fc505a7e-6886-4b8b-8077-743ce62bd5bb",
       "rows": [
        [
         "0",
         "2018-12-31 23:00:00+00:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "026396"
        ],
        [
         "1",
         "2019-01-01 00:00:00+00:00",
         "279.73291015625",
         "1.0",
         "281.1588439941406",
         "0.0",
         "0.1795746154797828",
         "3.3959695270888948",
         "8.370535714285714e-05",
         "026396"
        ],
        [
         "2",
         "2019-01-01 01:00:00+00:00",
         "279.1694030761719",
         "0.94149512052536",
         "280.8376770019531",
         "0.0",
         "0.2286955322921844",
         "3.4025789222907967",
         "8.426339285714286e-05",
         "026396"
        ],
        [
         "3",
         "2019-01-01 02:00:00+00:00",
         "278.66912841796875",
         "0.9989928603172302",
         "280.65997314453125",
         "0.0",
         "0.2266694432734434",
         "3.528859901378381",
         "8.537946428571428e-05",
         "026396"
        ],
        [
         "4",
         "2019-01-01 03:00:00+00:00",
         "278.27423095703125",
         "0.9902338981628418",
         "280.5801086425781",
         "0.0",
         "0.2848088968374169",
         "3.6035858398502567",
         "8.426339285714286e-05",
         "026396"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>d2m</th>\n",
       "      <th>tcc</th>\n",
       "      <th>t2m</th>\n",
       "      <th>ssr</th>\n",
       "      <th>angle10</th>\n",
       "      <th>speed10</th>\n",
       "      <th>load_factor</th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:00+00:00</td>\n",
       "      <td>279.732910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>281.158844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179575</td>\n",
       "      <td>3.395970</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 01:00:00+00:00</td>\n",
       "      <td>279.169403</td>\n",
       "      <td>0.941495</td>\n",
       "      <td>280.837677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>3.402579</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 02:00:00+00:00</td>\n",
       "      <td>278.669128</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>280.659973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226669</td>\n",
       "      <td>3.528860</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 03:00:00+00:00</td>\n",
       "      <td>278.274231</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>280.580109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284809</td>\n",
       "      <td>3.603586</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>026396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime         d2m       tcc         t2m  ssr   angle10  \\\n",
       "0 2018-12-31 23:00:00+00:00         NaN       NaN         NaN  NaN       NaN   \n",
       "1 2019-01-01 00:00:00+00:00  279.732910  1.000000  281.158844  0.0  0.179575   \n",
       "2 2019-01-01 01:00:00+00:00  279.169403  0.941495  280.837677  0.0  0.228696   \n",
       "3 2019-01-01 02:00:00+00:00  278.669128  0.998993  280.659973  0.0  0.226669   \n",
       "4 2019-01-01 03:00:00+00:00  278.274231  0.990234  280.580109  0.0  0.284809   \n",
       "\n",
       "    speed10  load_factor site_id  \n",
       "0       NaN          NaN  026396  \n",
       "1  3.395970     0.000084  026396  \n",
       "2  3.402579     0.000084  026396  \n",
       "3  3.528860     0.000085  026396  \n",
       "4  3.603586     0.000084  026396  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all aligned sites into one big dataframe\n",
    "solar_all_df = pd.concat(solar_site_data_aligned.values(), ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ Combined solar dataset shape:\", solar_all_df.shape)\n",
    "print(\"üîç Columns:\", solar_all_df.columns.tolist())\n",
    "\n",
    "# Check number of unique sites and timestamps\n",
    "print(\"üìå Unique site IDs:\", solar_all_df['site_id'].nunique())\n",
    "print(\"üìÜ Unique timestamps:\", solar_all_df['datetime'].nunique())\n",
    "\n",
    "# Optional: quick data preview\n",
    "display(solar_all_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QDC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
